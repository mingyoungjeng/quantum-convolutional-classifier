{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
                "from torch.optim import SGD, Adam\n",
                "from torch.nn import CrossEntropyLoss, MSELoss\n",
                "\n",
                "# from pennylane import NesterovMomentumOptimizer\n",
                "\n",
                "from qcc.ml.data import Data, BinaryData\n",
                "from qcc.ml.optimize import Optimizer\n",
                "from qcc.ml.data import ImageTransform, ImageTransform1D, ClassicalImageTransform\n",
                "from qcc.experiment import Experiment\n",
                "from qcc.ml.model import Model\n",
                "\n",
                "from pathlib import Path\n",
                "from qcc.file import new_dir\n",
                "\n",
                "from qcc.quantum.pennylane.ansatz import MQCCOptimized # as Module\n",
                "# from qcc.quantum.pennylane.ansatz import QCNN as Module\n",
                "# from qcc.ml.cnn import ConvolutionalNeuralNetwork as Module\n",
                "# from qcc.ml.mlp import MultiLayerPerceptron as Module\n",
                "# from qcc.ml.quanvolution import QuanvolutionalNeuralNetwork as Module\n",
                "from qcc.ml.quantum import MQCCNonHybrid as Module\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz.basic import BasicFiltering6\n",
                "from qcc.quantum.pennylane.pyramid import Pyramid\n",
                "from qcc.quantum.pennylane.c2q import ConvolutionAngleFilter, ConvolutionComplexAngleFilter, ConvolutionFilter\n",
                "from qcc.quantum.pennylane.local import define_filter\n",
                "from qcc.ml.quantum import AnsatzFilter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Meta parameters\n",
                "name = \"sdfljhvosdv\"\n",
                "filename = Path(f\"results/{name}\")\n",
                "num_trials = 1\n",
                "silent = False\n",
                "is_quantum = False\n",
                "\n",
                "# Ansatz parameters\n",
                "dims = (16, 16, 1)\n",
                "num_layers = 3\n",
                "module_options = {\n",
                "    \"U_kernel\": ConvolutionAngleFilter,\n",
                "    # \"pre_op\": True,\n",
                "    \"num_features\": 4,\n",
                "    # \"U_fully_connected\": ConvolutionAngleFilter,\n",
                "    # \"pooling\": True,\n",
                "    # \"kernel_shape\": (2, 2),\n",
                "    # \"q2c_method\": \"parity\"\n",
                "    # \"bias\": False\n",
                "    \"ansatz\": MQCCOptimized\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 21\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 78\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 20\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 68\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 19\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 62\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 33\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 131\n",
                        "2023-12-14 13:20:33,826: (mqccnonhybrid) Circuit ID: sdfljhvosdv\n",
                        "2023-12-14 13:20:33,827: (mqccnonhybrid) module=MQCCNonHybrid(\n",
                        "  (0): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (1): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (2): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (3): Flatten(start_dim=1, end_dim=-1)\n",
                        "  (4): FullyConnectedLayer(\n",
                        "    (fc): FullyConnected()\n",
                        "  )\n",
                        ")\n",
                        "2023-12-14 13:20:33,827: (mqccnonhybrid) data=BinaryData(dataset=<class 'torchvision.datasets.mnist.FashionMNIST'>, transform=image_transform_classical, target_transform=None, batch_size=(8, 8), classes=[0, 1])\n",
                        "2023-12-14 13:20:33,827: (mqccnonhybrid) optimizer=<class 'torch.optim.adam.Adam'>, self.args=(), self.kwargs={}\n",
                        "2023-12-14 13:20:33,827: (mqccnonhybrid) loss=CrossEntropyLoss()\n",
                        "2023-12-14 13:20:33,828: (mqccnonhybrid) num_trials=1\n",
                        "2023-12-14 13:20:33,828: (mqccnonhybrid) dims=(16, 16, 1)\n",
                        "2023-12-14 13:20:33,828: (mqccnonhybrid) num_layers=3\n",
                        "2023-12-14 13:20:33,828: (mqccnonhybrid) module_options={'U_kernel': <class 'qcc.quantum.pennylane.c2q.ConvolutionAngleFilter'>, 'num_features': 4, 'ansatz': <class 'qcc.quantum.pennylane.ansatz.mqcc_optimized.MQCCOptimized'>}\n"
                    ]
                }
            ],
            "source": [
                "filename = new_dir(filename, overwrite=True)\n",
                "filename = filename / name\n",
                "\n",
                "if is_quantum:\n",
                "    module = Module.from_dims\n",
                "else:\n",
                "    module = Module\n",
                "\n",
                "# Create module\n",
                "module = module(\n",
                "    dims,\n",
                "    num_layers=num_layers,\n",
                "    **module_options,\n",
                ")\n",
                "data = BinaryData(\n",
                "    FashionMNIST,\n",
                "    ImageTransform1D(dims) if is_quantum else ClassicalImageTransform(dims),\n",
                "    batch_size=(8,8),\n",
                ")\n",
                "optimizer = Optimizer(Adam)\n",
                "loss = CrossEntropyLoss()\n",
                "model = Model.with_logging(module, data, optimizer, loss, epoch=8)\n",
                "\n",
                "# Log important values\n",
                "model.logger.info(f\"Circuit ID: {name}\")\n",
                "model.logger.info(f\"{module=}\")\n",
                "model.logger.info(f\"{data=}\")\n",
                "model.logger.info(f\"{optimizer=}\")\n",
                "model.logger.info(f\"{loss=}\")\n",
                "\n",
                "model.logger.info(f\"{num_trials=}\")\n",
                "model.logger.info(f\"{dims=}\")\n",
                "model.logger.info(f\"{num_layers=}\")\n",
                "# model.logger.info(f\"{1=}\")\n",
                "model.logger.info(f\"{module_options=}\")\n",
                "\n",
                "# Save circuit drawing\n",
                "if is_quantum:\n",
                "    draw_path = filename.with_stem(f\"{name}_circuit\")\n",
                "    module.draw(filename=draw_path, decompose=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100.0%\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
                        "\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100.0%\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
                        "\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100.0%\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
                        "\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
                        "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100.0%\n",
                        "2023-12-14 13:21:09,545: (mqccnonhybrid) Number of Parameters: 82\n",
                        "/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/quantum/quantum.py:135: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3618.)\n",
                        "  data = data.reshape(size[::-1]).T\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
                        "\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-12-14 13:23:20,119: (mqccnonhybrid) (Epoch 1) Training took 128.06920 sec\n",
                        "2023-12-14 13:23:35,729: (mqccnonhybrid) (Epoch 1) Testing took: 15.38113 sec\n",
                        "2023-12-14 13:23:35,729: (mqccnonhybrid) (Epoch 1) Accuracy: 95.600%\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/math/utils.py:64\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[39m# Some frameworks may provide their own allclose implementation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     \u001b[39m# Try and use it if available.\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mallclose(a, b, rtol\u001b[39m=\u001b[39;49mrtol, atol\u001b[39m=\u001b[39;49matol, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Otherwise, convert the input to NumPy arrays.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39m#    np.abs(a - b) <= atol + rtol * np.abs(b)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m#\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/autoray/autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[0;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m backend \u001b[39m=\u001b[39m choose_backend(fn, \u001b[39m*\u001b[39margs, like\u001b[39m=\u001b[39mlike, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 80\u001b[0m \u001b[39mreturn\u001b[39;00m get_lib_fn(backend, fn)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "\u001b[0;31mTypeError\u001b[0m: allclose(): argument 'other' (position 2) must be Tensor, not float",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(model, num_trials, results_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# experiment.partial(silent=silent)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m experiment(filename\u001b[39m=\u001b[39;49mfilename)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:160\u001b[0m, in \u001b[0;36mExperiment.__call__\u001b[0;34m(self, filename, parallel)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_trials):\n\u001b[0;32m--> 160\u001b[0m         dfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_trial(i \u001b[39m+\u001b[39;49m offset, rename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_trials \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    161\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_dfs(dfs, filename)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdfs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:74\u001b[0m, in \u001b[0;36mExperiment._run_trial\u001b[0;34m(self, idx, cls, rename)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m Logger\u001b[39m.\u001b[39mcopy(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger, name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_trial_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39m# Perform trial and get results\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m results_df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mDataFrame([\u001b[39mcls\u001b[39;49m()], schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_schema)\n\u001b[1;32m     76\u001b[0m \u001b[39m# Combine DataFrames\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m rename:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/model.py:68\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, params, silent)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# ==== Training ==== #\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     now \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time()\n\u001b[0;32m---> 68\u001b[0m     parameters \u001b[39m=\u001b[39m train(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, opt, training_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cost)\n\u001b[1;32m     69\u001b[0m     training_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time() \u001b[39m-\u001b[39m now\n\u001b[1;32m     71\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining took \u001b[39m\u001b[39m{\u001b[39;00mtraining_time\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/optimize.py:116\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(fn, optimizer, training_dataloader, cost_fn, epoch, params)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[39mif\u001b[39;00m USE_CUDA:\n\u001b[1;32m    115\u001b[0m             data, labels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m), labels\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m         predictions \u001b[39m=\u001b[39m fn(data) \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m fn(data, params)\n\u001b[1;32m    117\u001b[0m         backpropagate(predictions, labels, optimizer, cost_fn)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m optimizer\u001b[39m.\u001b[39mparameters\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/quantum.py:220\u001b[0m, in \u001b[0;36mMQCCLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    217\u001b[0m magnitudes \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mnorm(inputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    218\u001b[0m inputs \u001b[39m=\u001b[39m (inputs\u001b[39m.\u001b[39mT \u001b[39m/\u001b[39m magnitudes)\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 220\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmqcc\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m    222\u001b[0m \u001b[39m# Unnormalize output\u001b[39;00m\n\u001b[1;32m    223\u001b[0m result \u001b[39m=\u001b[39m (result\u001b[39m.\u001b[39mT \u001b[39m/\u001b[39m magnitudes)\u001b[39m.\u001b[39mT\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/quantum/pennylane/ansatz/ansatz.py:148\u001b[0m, in \u001b[0;36mAnsatz.forward\u001b[0;34m(self, psi_in)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, psi_in: Statevector | None \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 148\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(psi_in\u001b[39m=\u001b[39;49mpsi_in)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     \u001b[39mmatch\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq2c_method:\n\u001b[1;32m    151\u001b[0m         \u001b[39mcase\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mQ2CMethod\u001b[39m.\u001b[39mExpectationValue:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnode.py:974\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m         kwargs[\u001b[39m\"\u001b[39m\u001b[39mshots\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_device_shots(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_device)\n\u001b[1;32m    973\u001b[0m \u001b[39m# construct the tape\u001b[39;00m\n\u001b[0;32m--> 974\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstruct(args, kwargs)\n\u001b[1;32m    976\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    977\u001b[0m using_custom_cache \u001b[39m=\u001b[39m (\n\u001b[1;32m    978\u001b[0m     \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__getitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    979\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__setitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    980\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(cache, \u001b[39m\"\u001b[39m\u001b[39m__delitem__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    981\u001b[0m )\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnode.py:872\u001b[0m, in \u001b[0;36mQNode.construct\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[39mif\u001b[39;00m old_interface \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    870\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minterface \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mget_interface(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mvalues()))\n\u001b[0;32m--> 872\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tape \u001b[39m=\u001b[39m make_qscript(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc, shots)(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    873\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39m_qfunc_output\n\u001b[1;32m    875\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtape\u001b[39m.\u001b[39mget_parameters(trainable_only\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/tape/qscript.py:1531\u001b[0m, in \u001b[0;36mmake_qscript.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1530\u001b[0m     \u001b[39mwith\u001b[39;00m AnnotatedQueue() \u001b[39mas\u001b[39;00m q:\n\u001b[0;32m-> 1531\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1533\u001b[0m     qscript \u001b[39m=\u001b[39m QuantumScript\u001b[39m.\u001b[39mfrom_queue(q, shots)\n\u001b[1;32m   1534\u001b[0m     qscript\u001b[39m.\u001b[39m_qfunc_output \u001b[39m=\u001b[39m result\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/quantum/pennylane/ansatz/ansatz.py:143\u001b[0m, in \u001b[0;36mAnsatz._circuit\u001b[0;34m(self, psi_in, params)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_circuit\u001b[39m(\n\u001b[1;32m    138\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    139\u001b[0m     psi_in: Statevector | None \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m     params: Parameters | None \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    141\u001b[0m ):\n\u001b[1;32m    142\u001b[0m     \u001b[39mif\u001b[39;00m psi_in \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# this is done to facilitate drawing\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc2q(psi_in)\n\u001b[1;32m    144\u001b[0m     meas \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcircuit(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters() \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m params)\n\u001b[1;32m    145\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq2c(meas)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/quantum/pennylane/ansatz/ansatz.py:121\u001b[0m, in \u001b[0;36mAnsatz.c2q\u001b[0;34m(self, psi_in)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mc2q\u001b[39m(\u001b[39mself\u001b[39m, psi_in: Statevector) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Operation:\n\u001b[1;32m    120\u001b[0m     wires \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_wires[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m--> 121\u001b[0m     \u001b[39mreturn\u001b[39;00m AmplitudeEmbedding(psi_in, wires, pad_with\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/templates/embeddings/amplitude.py:130\u001b[0m, in \u001b[0;36mAmplitudeEmbedding.__init__\u001b[0;34m(self, features, wires, pad_with, normalize, id)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpad_with \u001b[39m=\u001b[39m pad_with\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnormalize \u001b[39m=\u001b[39m normalize\n\u001b[0;32m--> 130\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preprocess(features, wires, pad_with, normalize)\n\u001b[1;32m    131\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(features, wires\u001b[39m=\u001b[39mwires, \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mid\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/templates/embeddings/amplitude.py:225\u001b[0m, in \u001b[0;36mAmplitudeEmbedding._preprocess\u001b[0;34m(features, wires, pad_with, normalize)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m normalize \u001b[39mor\u001b[39;00m pad_with:\n\u001b[1;32m    223\u001b[0m         feature_set \u001b[39m=\u001b[39m feature_set \u001b[39m/\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msqrt(norm)\n\u001b[0;32m--> 225\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m qml\u001b[39m.\u001b[39;49mmath\u001b[39m.\u001b[39;49mallclose(norm, \u001b[39m1.0\u001b[39;49m, atol\u001b[39m=\u001b[39;49mTOLERANCE):\n\u001b[1;32m    226\u001b[0m     \u001b[39mif\u001b[39;00m normalize \u001b[39mor\u001b[39;00m pad_with:\n\u001b[1;32m    227\u001b[0m         feature_set \u001b[39m=\u001b[39m feature_set \u001b[39m/\u001b[39m qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39msqrt(norm)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/math/utils.py:73\u001b[0m, in \u001b[0;36mallclose\u001b[0;34m(a, b, rtol, atol, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mallclose(a, b, rtol\u001b[39m=\u001b[39mrtol, atol\u001b[39m=\u001b[39matol, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mRuntimeError\u001b[39;00m):\n\u001b[1;32m     66\u001b[0m     \u001b[39m# Otherwise, convert the input to NumPy arrays.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39m#    np.abs(a - b) <= atol + rtol * np.abs(b)\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[39m#\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     t1 \u001b[39m=\u001b[39m ar\u001b[39m.\u001b[39;49mto_numpy(a)\n\u001b[1;32m     74\u001b[0m     t2 \u001b[39m=\u001b[39m ar\u001b[39m.\u001b[39mto_numpy(b)\n\u001b[1;32m     75\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mallclose(t1, t2, rtol\u001b[39m=\u001b[39mrtol, atol\u001b[39m=\u001b[39matol, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/autoray/autoray.py:1057\u001b[0m, in \u001b[0;36mto_numpy\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m   1054\u001b[0m         \u001b[39mreturn\u001b[39;00m do(\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m, x, dtype, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m-> 1057\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_numpy\u001b[39m(x):\n\u001b[1;32m   1058\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get a numpy version of array ``x``.\"\"\"\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m     \u001b[39mreturn\u001b[39;00m do(\u001b[39m\"\u001b[39m\u001b[39mto_numpy\u001b[39m\u001b[39m\"\u001b[39m, x)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Run experiment\n",
                "results_schema = [\"accuracy\", \"training_time\", \"testing_time\"]\n",
                "experiment = Experiment(model, num_trials, results_schema)\n",
                "# experiment.partial(silent=silent)\n",
                "results = experiment(filename=filename)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print accuracy results\n",
                "metrics = (\"median\", \"mean\", \"max\", \"min\", \"std\")\n",
                "for name in results.columns:\n",
                "    col = results[name]\n",
                "    msg = (f\"{metric}={getattr(col, metric)()}\" for metric in metrics)\n",
                "    msg = \", \".join(msg)\n",
                "    msg = f\"{name}: {msg}\"\n",
                "    model.logger.info(msg)\n",
                "\n",
                "# Save aggregated loss history figure\n",
                "display(experiment.draw(filename))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c7967d85baf232544f00baec60c53642b018367ac4c489b1a4dde60b922cc6fa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
