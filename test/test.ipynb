{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
                "from torch.optim import SGD, Adam\n",
                "from torch.nn import CrossEntropyLoss, MSELoss\n",
                "\n",
                "# from pennylane import NesterovMomentumOptimizer\n",
                "\n",
                "from qcc.ml.data import Data, BinaryData\n",
                "from qcc.ml.optimize import Optimizer\n",
                "from qcc.ml.data import ImageTransform, ImageTransform1D, ClassicalImageTransform\n",
                "from qcc.experiment import Experiment\n",
                "from qcc.ml.model import Model\n",
                "\n",
                "from pathlib import Path\n",
                "from qcc.file import new_dir\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz import MQCCOptimized # as Module\n",
                "# from qcc.quantum.pennylane.ansatz import QCNN as Module\n",
                "# from qcc.ml.cnn import ConvolutionalNeuralNetwork as Module\n",
                "# from qcc.ml.mlp import MultiLayerPerceptron as Module\n",
                "from qcc.quantum.quanvolution import QuanvolutionalNeuralNetwork as Module\n",
                "# from qcc.ml.hybrid_cnn import MQCCNonHybrid as Module\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz.basic import BasicFiltering6\n",
                "from qcc.quantum.pennylane.pyramid import Pyramid\n",
                "from qcc.quantum.pennylane.c2q import ConvolutionAngleFilter, ConvolutionComplexAngleFilter, ConvolutionFilter\n",
                "from qcc.quantum.pennylane.local import define_filter\n",
                "from qcc.ml.hybrid_cnn import AnsatzFilter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Meta parameters\n",
                "name = \"sdfljhvosdv\"\n",
                "filename = Path(f\"results/{name}\")\n",
                "num_trials = 1\n",
                "silent = False\n",
                "is_quantum = False\n",
                "\n",
                "# Ansatz parameters\n",
                "dims = (16, 16, 3)\n",
                "num_layers = 4\n",
                "module_options = {\n",
                "    # \"U_filter\": ConvolutionAngleFilter,\n",
                "    # \"pre_op\": True,\n",
                "    # \"num_features\": 4,\n",
                "    # \"U_fully_connected\": ConvolutionAngleFilter,\n",
                "    # \"pooling\": True,\n",
                "    # \"filter_shape\": (2, 2),\n",
                "    # \"q2c_method\": \"parity\"\n",
                "    # \"bias\": False\n",
                "    # \"ansatz\": MQCCOptimized\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-11-20 19:01:53,189: (quanvolutionalneuralnetwork) Circuit ID: sdfljhvosdv\n",
                        "2023-11-20 19:01:53,190: (quanvolutionalneuralnetwork) module=QuanvolutionalNeuralNetwork(\n",
                        "  (0): Quanvolution(\n",
                        "    (qnode): <Quantum Torch Layer: func=circuit>\n",
                        "  )\n",
                        "  (1): ConvolutionalNeuralNetwork(\n",
                        "    (0): Conv2d(12, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
                        "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
                        "    (2): ReLU()\n",
                        "    (3): Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
                        "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
                        "    (5): ReLU()\n",
                        "    (6): Conv2d(1, 1, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1), padding_mode=circular)\n",
                        "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
                        "    (8): ReLU()\n",
                        "    (9): Flatten(start_dim=1, end_dim=-1)\n",
                        "    (10): Linear(in_features=1, out_features=2, bias=True)\n",
                        "  )\n",
                        ")\n",
                        "2023-11-20 19:01:53,190: (quanvolutionalneuralnetwork) data=BinaryData(dataset=<class 'torchvision.datasets.cifar.CIFAR10'>, transform=image_transform_classical, target_transform=None, batch_size=(8, 8), classes=[0, 1])\n",
                        "2023-11-20 19:01:53,190: (quanvolutionalneuralnetwork) optimizer=<class 'torch.optim.adam.Adam'>, self.args=(), self.kwargs={}\n",
                        "2023-11-20 19:01:53,191: (quanvolutionalneuralnetwork) loss=CrossEntropyLoss()\n",
                        "2023-11-20 19:01:53,191: (quanvolutionalneuralnetwork) num_trials=1\n",
                        "2023-11-20 19:01:53,191: (quanvolutionalneuralnetwork) dims=(16, 16, 3)\n",
                        "2023-11-20 19:01:53,191: (quanvolutionalneuralnetwork) num_layers=4\n",
                        "2023-11-20 19:01:53,192: (quanvolutionalneuralnetwork) module_options={}\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(16, 16, 3) 3\n"
                    ]
                }
            ],
            "source": [
                "filename = new_dir(filename, overwrite=True)\n",
                "filename = filename / name\n",
                "\n",
                "if is_quantum:\n",
                "    module = Module.from_dims\n",
                "else:\n",
                "    module = Module\n",
                "\n",
                "# Create module\n",
                "module = module(\n",
                "    dims,\n",
                "    num_layers=num_layers,\n",
                "    **module_options,\n",
                ")\n",
                "data = BinaryData(\n",
                "    CIFAR10,\n",
                "    ImageTransform(dims) if is_quantum else ClassicalImageTransform(dims),\n",
                "    batch_size=(8,8),\n",
                ")\n",
                "optimizer = Optimizer(Adam)\n",
                "loss = CrossEntropyLoss()\n",
                "model = Model.with_logging(module, data, optimizer, loss, epoch=8)\n",
                "\n",
                "# Log important values\n",
                "model.logger.info(f\"Circuit ID: {name}\")\n",
                "model.logger.info(f\"{module=}\")\n",
                "model.logger.info(f\"{data=}\")\n",
                "model.logger.info(f\"{optimizer=}\")\n",
                "model.logger.info(f\"{loss=}\")\n",
                "\n",
                "model.logger.info(f\"{num_trials=}\")\n",
                "model.logger.info(f\"{dims=}\")\n",
                "model.logger.info(f\"{num_layers=}\")\n",
                "# model.logger.info(f\"{1=}\")\n",
                "model.logger.info(f\"{module_options=}\")\n",
                "\n",
                "# Save circuit drawing\n",
                "if is_quantum:\n",
                "    draw_path = filename.with_stem(f\"{name}_circuit\")\n",
                "    module.draw(filename=draw_path, decompose=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-11-20 19:01:54,547: (quanvolutionalneuralnetwork) Number of Parameters: 63\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m/Users/mingyoungjeng/Documents/Spring 2023.nosync/quantum-convolutional-classifier/test/test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(model, num_trials, results_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# experiment.partial(silent=silent)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m experiment(filename\u001b[39m=\u001b[39;49mfilename)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:154\u001b[0m, in \u001b[0;36mExperiment.__call__\u001b[0;34m(self, filename, parallel)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_trials):\n\u001b[0;32m--> 154\u001b[0m         dfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_trial(i \u001b[39m+\u001b[39;49m offset, rename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_trials \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_dfs(dfs, filename)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdfs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:68\u001b[0m, in \u001b[0;36mExperiment._run_trial\u001b[0;34m(self, idx, cls, rename)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m Logger\u001b[39m.\u001b[39mcopy(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger, name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_trial_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Perform trial and get results\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m results_df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mDataFrame([\u001b[39mcls\u001b[39;49m()], schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_schema)\n\u001b[1;32m     70\u001b[0m \u001b[39m# Combine DataFrames\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m rename:\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/ml/model.py:46\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, params, silent)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch):\n\u001b[1;32m     45\u001b[0m     now \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time()\n\u001b[0;32m---> 46\u001b[0m     parameters \u001b[39m=\u001b[39m train(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, opt, training_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cost)\n\u001b[1;32m     47\u001b[0m     training_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time() \u001b[39m-\u001b[39m now\n\u001b[1;32m     49\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining took \u001b[39m\u001b[39m{\u001b[39;00mtraining_time\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/ml/optimize.py:116\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(fn, optimizer, training_dataloader, cost_fn, epoch, params)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[39mif\u001b[39;00m USE_CUDA:\n\u001b[1;32m    115\u001b[0m             data, labels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m), labels\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m         predictions \u001b[39m=\u001b[39m fn(data) \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m fn(data, params)\n\u001b[1;32m    117\u001b[0m         backpropagate(predictions, labels, optimizer, cost_fn)\n\u001b[1;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m optimizer\u001b[39m.\u001b[39mparameters\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/quantum/quanvolution.py:108\u001b[0m, in \u001b[0;36mQuanvolution.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mreshape(qnode_shape)\n\u001b[1;32m    107\u001b[0m \u001b[39m# Quanvolution\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m output: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    110\u001b[0m \u001b[39m# Normalize back to 0-1\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39m# output = (output + 1) / 2\u001b[39;00m\n\u001b[1;32m    113\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mreshape(unfold_shape)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnn/torch.py:408\u001b[0m, in \u001b[0;36mTorchLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    405\u001b[0m     results \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(reconstructor)\n\u001b[1;32m    406\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     \u001b[39m# calculate the forward pass as usual\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_evaluate_qnode(inputs)\n\u001b[1;32m    410\u001b[0m \u001b[39m# reshape to the correct number of batch dims\u001b[39;00m\n\u001b[1;32m    411\u001b[0m \u001b[39mif\u001b[39;00m has_batch_dim:\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnn/torch.py:429\u001b[0m, in \u001b[0;36mTorchLayer._evaluate_qnode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Evaluates the QNode for a single input datapoint.\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \n\u001b[1;32m    419\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39m    tensor: output datapoint\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    425\u001b[0m kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    426\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_arg: x},\n\u001b[1;32m    427\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{arg: weight\u001b[39m.\u001b[39mto(x) \u001b[39mfor\u001b[39;00m arg, weight \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mqnode_weights\u001b[39m.\u001b[39mitems()},\n\u001b[1;32m    428\u001b[0m }\n\u001b[0;32m--> 429\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, torch\u001b[39m.\u001b[39mTensor):\n\u001b[1;32m    432\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mtype(x\u001b[39m.\u001b[39mdtype)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnode.py:989\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    988\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    990\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,),\n\u001b[1;32m    991\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    992\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[1;32m    993\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[1;32m    994\u001b[0m     transform_program\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_program,\n\u001b[1;32m    995\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[1;32m    996\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[1;32m    997\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[1;32m    998\u001b[0m )\n\u001b[1;32m   1000\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1002\u001b[0m \u001b[39m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:636\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 636\u001b[0m     results \u001b[39m=\u001b[39m inner_execute(tapes)\n\u001b[1;32m    637\u001b[0m     results \u001b[39m=\u001b[39m batch_fn(results)\n\u001b[1;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m program_post_processing(results)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:255\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m numpy_only:\n\u001b[1;32m    254\u001b[0m     tapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(qml\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tapes)\n\u001b[0;32m--> 255\u001b[0m \u001b[39mreturn\u001b[39;00m cached_device_execution(tapes)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:338\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    335\u001b[0m repeated \u001b[39m=\u001b[39m {}\n\u001b[1;32m    337\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n\u001b[0;32m--> 338\u001b[0m     h \u001b[39m=\u001b[39m tape\u001b[39m.\u001b[39;49mhash\n\u001b[1;32m    340\u001b[0m     \u001b[39mif\u001b[39;00m h \u001b[39min\u001b[39;00m hashes\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    341\u001b[0m         \u001b[39m# Tape already exists within ``tapes``. Determine the\u001b[39;00m\n\u001b[1;32m    342\u001b[0m         \u001b[39m# index of the first occurrence of the tape, store this,\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         \u001b[39m# and continue to the next iteration.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         idx \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(hashes\u001b[39m.\u001b[39mkeys())[\u001b[39mlist\u001b[39m(hashes\u001b[39m.\u001b[39mvalues())\u001b[39m.\u001b[39mindex(h)]\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/tape/qscript.py:229\u001b[0m, in \u001b[0;36mQuantumScript.hash\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m fingerprint \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 229\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(op\u001b[39m.\u001b[39mhash \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moperations)\n\u001b[1;32m    230\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(m\u001b[39m.\u001b[39mhash \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurements)\n\u001b[1;32m    231\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_params)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/tape/qscript.py:229\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m fingerprint \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 229\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(op\u001b[39m.\u001b[39;49mhash \u001b[39mfor\u001b[39;00m op \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moperations)\n\u001b[1;32m    230\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(m\u001b[39m.\u001b[39mhash \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeasurements)\n\u001b[1;32m    231\u001b[0m fingerprint\u001b[39m.\u001b[39mextend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainable_params)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/operation.py:718\u001b[0m, in \u001b[0;36mOperator.hash\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    710\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m    711\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhash\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    712\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"int: Integer hash that uniquely represents the operator.\"\"\"\u001b[39;00m\n\u001b[1;32m    713\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mhash\u001b[39m(\n\u001b[1;32m    714\u001b[0m         (\n\u001b[1;32m    715\u001b[0m             \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname),\n\u001b[1;32m    716\u001b[0m             \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwires\u001b[39m.\u001b[39mtolist()),\n\u001b[1;32m    717\u001b[0m             \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhyperparameters\u001b[39m.\u001b[39mvalues()),\n\u001b[0;32m--> 718\u001b[0m             _process_data(\u001b[39mself\u001b[39;49m),\n\u001b[1;32m    719\u001b[0m         )\n\u001b[1;32m    720\u001b[0m     )\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/operation.py:383\u001b[0m, in \u001b[0;36m_process_data\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_process_data\u001b[39m(op):\n\u001b[1;32m    379\u001b[0m     \u001b[39m# Use qml.math.real to take the real part. We may get complex inputs for\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[39m# example when differentiating holomorphic functions with JAX: a complex\u001b[39;00m\n\u001b[1;32m    381\u001b[0m     \u001b[39m# valued QNode (one that returns qml.state) requires complex typed inputs.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m     \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mRX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRY\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRZ\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPhaseShift\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mRot\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 383\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m([qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mround(qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreal(d) \u001b[39m%\u001b[39m (\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi), \u001b[39m10\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m op\u001b[39m.\u001b[39mdata])\n\u001b[1;32m    385\u001b[0m     \u001b[39mif\u001b[39;00m op\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39mCRX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCRY\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCRZ\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCRot\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    386\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mstr\u001b[39m([qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mround(qml\u001b[39m.\u001b[39mmath\u001b[39m.\u001b[39mreal(d) \u001b[39m%\u001b[39m (\u001b[39m4\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi), \u001b[39m10\u001b[39m) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m op\u001b[39m.\u001b[39mdata])\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/_tensor_str.py:662\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_str\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, tensor_contents\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 662\u001b[0m     \u001b[39mwith\u001b[39;49;00m torch\u001b[39m.\u001b[39;49mno_grad(), torch\u001b[39m.\u001b[39;49mutils\u001b[39m.\u001b[39;49m_python_dispatch\u001b[39m.\u001b[39;49m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m         guard \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_DisableFuncTorch()\n\u001b[1;32m    664\u001b[0m         \u001b[39mreturn\u001b[39;49;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/autograd/grad_mode.py:80\u001b[0m, in \u001b[0;36mno_grad.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_grad_enabled()\n\u001b[0;32m---> 80\u001b[0m     torch\u001b[39m.\u001b[39;49mset_grad_enabled(\u001b[39mFalse\u001b[39;49;00m)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/autograd/grad_mode.py:184\u001b[0m, in \u001b[0;36mset_grad_enabled.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, mode: \u001b[39mbool\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 184\u001b[0m     torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_set_grad_enabled(mode)\n\u001b[1;32m    185\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m=\u001b[39m mode\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Run experiment\n",
                "results_schema = [\"accuracy\", \"training_time\", \"testing_time\"]\n",
                "experiment = Experiment(model, num_trials, results_schema)\n",
                "# experiment.partial(silent=silent)\n",
                "results = experiment(filename=filename)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print accuracy results\n",
                "metrics = (\"median\", \"mean\", \"max\", \"min\", \"std\")\n",
                "for name in results.columns:\n",
                "    col = results[name]\n",
                "    msg = (f\"{metric}={getattr(col, metric)()}\" for metric in metrics)\n",
                "    msg = \", \".join(msg)\n",
                "    msg = f\"{name}: {msg}\"\n",
                "    model.logger.info(msg)\n",
                "\n",
                "# Save aggregated loss history figure\n",
                "display(experiment.draw(filename))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c7967d85baf232544f00baec60c53642b018367ac4c489b1a4dde60b922cc6fa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
