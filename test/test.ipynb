{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
                "from torch.optim import SGD, Adam\n",
                "from torch.nn import CrossEntropyLoss, MSELoss\n",
                "\n",
                "# from pennylane import NesterovMomentumOptimizer\n",
                "\n",
                "from qcc.ml.data import Data, BinaryData\n",
                "from qcc.ml.optimize import Optimizer\n",
                "from qcc.ml.data import ImageTransform, ImageTransform1D, ClassicalImageTransform\n",
                "from qcc.experiment import Experiment\n",
                "from qcc.ml.model import Model\n",
                "\n",
                "from pathlib import Path\n",
                "from qcc.file import new_dir\n",
                "\n",
                "from qcc.quantum.pennylane.ansatz import MQCCOptimized # as Module\n",
                "# from qcc.quantum.pennylane.ansatz import QCNN as Module\n",
                "# from qcc.ml.cnn import ConvolutionalNeuralNetwork as Module\n",
                "# from qcc.ml.mlp import MultiLayerPerceptron as Module\n",
                "# from qcc.ml.quanvolution import QuanvolutionalNeuralNetwork as Module\n",
                "from qcc.ml.quantum import MQCCNonHybrid as Module\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz.basic import BasicFiltering6\n",
                "from qcc.quantum.pennylane.pyramid import Pyramid\n",
                "from qcc.quantum.pennylane.c2q import ConvolutionAngleFilter, ConvolutionComplexAngleFilter, ConvolutionFilter\n",
                "from qcc.quantum.pennylane.local import define_filter\n",
                "from qcc.ml.quantum import AnsatzFilter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Meta parameters\n",
                "name = \"sdfljhvosdv\"\n",
                "filename = Path(f\"results/{name}\")\n",
                "num_trials = 1\n",
                "silent = False\n",
                "is_quantum = False\n",
                "\n",
                "# Ansatz parameters\n",
                "dims = (16, 16, 1)\n",
                "num_layers = 3\n",
                "module_options = {\n",
                "    \"U_kernel\": ConvolutionAngleFilter,\n",
                "    # \"pre_op\": True,\n",
                "    \"num_features\": 4,\n",
                "    # \"U_fully_connected\": ConvolutionAngleFilter,\n",
                "    # \"pooling\": True,\n",
                "    # \"kernel_shape\": (2, 2),\n",
                "    # \"q2c_method\": \"parity\"\n",
                "    # \"bias\": False\n",
                "    \"ansatz\": MQCCOptimized\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 21\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 78\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 20\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 68\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 19\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 62\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Depth: 33\n",
                        "INFO:qcc.quantum.pennylane.ansatz.ansatz:Gate Count: 131\n",
                        "2023-12-15 11:17:18,163: (mqccnonhybrid) Circuit ID: sdfljhvosdv\n",
                        "2023-12-15 11:17:18,163: (mqccnonhybrid) module=MQCCNonHybrid(\n",
                        "  (0): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (1): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (2): MQCCLayer(\n",
                        "    (mqcc): MQCCOptimized()\n",
                        "  )\n",
                        "  (3): Flatten(start_dim=1, end_dim=-1)\n",
                        "  (4): FullyConnectedLayer(\n",
                        "    (fc): FullyConnected()\n",
                        "  )\n",
                        ")\n",
                        "2023-12-15 11:17:18,163: (mqccnonhybrid) data=BinaryData(dataset=<class 'torchvision.datasets.mnist.FashionMNIST'>, transform=image_transform_classical, target_transform=None, batch_size=(8, 8), classes=[0, 1])\n",
                        "2023-12-15 11:17:18,164: (mqccnonhybrid) optimizer=<class 'torch.optim.adam.Adam'>, self.args=(), self.kwargs={}\n",
                        "2023-12-15 11:17:18,164: (mqccnonhybrid) loss=CrossEntropyLoss()\n",
                        "2023-12-15 11:17:18,164: (mqccnonhybrid) num_trials=1\n",
                        "2023-12-15 11:17:18,165: (mqccnonhybrid) dims=(16, 16, 1)\n",
                        "2023-12-15 11:17:18,165: (mqccnonhybrid) num_layers=3\n",
                        "2023-12-15 11:17:18,165: (mqccnonhybrid) module_options={'U_kernel': <class 'qcc.quantum.pennylane.c2q.ConvolutionAngleFilter'>, 'num_features': 4, 'ansatz': <class 'qcc.quantum.pennylane.ansatz.mqcc_optimized.MQCCOptimized'>}\n"
                    ]
                }
            ],
            "source": [
                "filename = new_dir(filename, overwrite=True)\n",
                "filename = filename / name\n",
                "\n",
                "if is_quantum:\n",
                "    module = Module.from_dims\n",
                "else:\n",
                "    module = Module\n",
                "\n",
                "# Create module\n",
                "module = module(\n",
                "    dims,\n",
                "    num_layers=num_layers,\n",
                "    **module_options,\n",
                ")\n",
                "data = BinaryData(\n",
                "    FashionMNIST,\n",
                "    ImageTransform1D(dims) if is_quantum else ClassicalImageTransform(dims),\n",
                "    batch_size=(8,8),\n",
                ")\n",
                "optimizer = Optimizer(Adam)\n",
                "loss = CrossEntropyLoss()\n",
                "model = Model.with_logging(module, data, optimizer, loss, epoch=8)\n",
                "\n",
                "# Log important values\n",
                "model.logger.info(f\"Circuit ID: {name}\")\n",
                "model.logger.info(f\"{module=}\")\n",
                "model.logger.info(f\"{data=}\")\n",
                "model.logger.info(f\"{optimizer=}\")\n",
                "model.logger.info(f\"{loss=}\")\n",
                "\n",
                "model.logger.info(f\"{num_trials=}\")\n",
                "model.logger.info(f\"{dims=}\")\n",
                "model.logger.info(f\"{num_layers=}\")\n",
                "# model.logger.info(f\"{1=}\")\n",
                "model.logger.info(f\"{module_options=}\")\n",
                "\n",
                "# Save circuit drawing\n",
                "if is_quantum:\n",
                "    draw_path = filename.with_stem(f\"{name}_circuit\")\n",
                "    module.draw(filename=draw_path, decompose=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-12-15 11:17:18,194: (mqccnonhybrid) Number of Parameters: 82\n",
                        "/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/quantum.py:246: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3618.)\n",
                        "  result = result.T  # Return in row-major order\n",
                        "2023-12-15 11:19:20,223: (mqccnonhybrid) (Epoch 1) Training took 120.79609 sec\n",
                        "2023-12-15 11:19:34,600: (mqccnonhybrid) (Epoch 1) Testing took: 14.20183 sec\n",
                        "2023-12-15 11:19:34,601: (mqccnonhybrid) (Epoch 1) Accuracy: 90.600%\n",
                        "2023-12-15 11:21:37,634: (mqccnonhybrid) (Epoch 2) Training took 242.59370 sec\n",
                        "2023-12-15 11:21:52,067: (mqccnonhybrid) (Epoch 2) Testing took: 14.29028 sec\n",
                        "2023-12-15 11:21:52,068: (mqccnonhybrid) (Epoch 2) Accuracy: 92.350%\n",
                        "2023-12-15 11:23:52,923: (mqccnonhybrid) (Epoch 3) Training took 362.39289 sec\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(model, num_trials, results_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# experiment.partial(silent=silent)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/repos.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m experiment(filename\u001b[39m=\u001b[39;49mfilename)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:160\u001b[0m, in \u001b[0;36mExperiment.__call__\u001b[0;34m(self, filename, parallel)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_trials):\n\u001b[0;32m--> 160\u001b[0m         dfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_trial(i \u001b[39m+\u001b[39;49m offset, rename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_trials \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    161\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_dfs(dfs, filename)\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdfs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:74\u001b[0m, in \u001b[0;36mExperiment._run_trial\u001b[0;34m(self, idx, cls, rename)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m Logger\u001b[39m.\u001b[39mcopy(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger, name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_trial_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39m# Perform trial and get results\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m results_df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mDataFrame([\u001b[39mcls\u001b[39;49m()], schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_schema)\n\u001b[1;32m     76\u001b[0m \u001b[39m# Combine DataFrames\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m rename:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/model.py:76\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, params, silent)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39m# ==== Testing ==== #\u001b[39;00m\n\u001b[1;32m     75\u001b[0m now \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time()\n\u001b[0;32m---> 76\u001b[0m accuracy \u001b[39m=\u001b[39m test(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, testing_dataloader, parameters)\n\u001b[1;32m     77\u001b[0m testing_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time() \u001b[39m-\u001b[39m now\n\u001b[1;32m     79\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTesting took: \u001b[39m\u001b[39m{\u001b[39;00mtesting_time\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/optimize.py:134\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(fn, testing_dataloader, params)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mif\u001b[39;00m USE_CUDA:\n\u001b[1;32m    133\u001b[0m     data, labels \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m), labels\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 134\u001b[0m predictions \u001b[39m=\u001b[39m fn(data) \u001b[39mif\u001b[39;00m params \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m fn(data, params)\n\u001b[1;32m    135\u001b[0m predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(predictions, \u001b[39m1\u001b[39m)\n\u001b[1;32m    136\u001b[0m correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcount_nonzero(predictions \u001b[39m==\u001b[39m labels)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/ml/quantum.py:226\u001b[0m, in \u001b[0;36mMQCCLayer.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    223\u001b[0m magnitudes \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39mnorm(inputs, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    224\u001b[0m inputs \u001b[39m=\u001b[39m (inputs\u001b[39m.\u001b[39mT \u001b[39m/\u001b[39m magnitudes)\u001b[39m.\u001b[39mT\n\u001b[0;32m--> 226\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmqcc\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[1;32m    228\u001b[0m \u001b[39m# Unnormalize output\u001b[39;00m\n\u001b[1;32m    229\u001b[0m result \u001b[39m=\u001b[39m (result\u001b[39m.\u001b[39mT \u001b[39m/\u001b[39m magnitudes)\u001b[39m.\u001b[39mT\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/src/qcc/quantum/pennylane/ansatz/ansatz.py:147\u001b[0m, in \u001b[0;36mAnsatz.forward\u001b[0;34m(self, psi_in)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, psi_in: Statevector \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mqnode(psi_in\u001b[39m=\u001b[39;49mpsi_in)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    149\u001b[0m     \u001b[39mmatch\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq2c_method:\n\u001b[1;32m    150\u001b[0m         \u001b[39mcase\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mQ2CMethod\u001b[39m.\u001b[39mExpectationValue:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/qnode.py:989\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    986\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecute_kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmode\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    988\u001b[0m \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m--> 989\u001b[0m res \u001b[39m=\u001b[39m qml\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    990\u001b[0m     (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tape,),\n\u001b[1;32m    991\u001b[0m     device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[1;32m    992\u001b[0m     gradient_fn\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_fn,\n\u001b[1;32m    993\u001b[0m     interface\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterface,\n\u001b[1;32m    994\u001b[0m     transform_program\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_program,\n\u001b[1;32m    995\u001b[0m     gradient_kwargs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgradient_kwargs,\n\u001b[1;32m    996\u001b[0m     override_shots\u001b[39m=\u001b[39;49moverride_shots,\n\u001b[1;32m    997\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_kwargs,\n\u001b[1;32m    998\u001b[0m )\n\u001b[1;32m   1000\u001b[0m res \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1002\u001b[0m \u001b[39m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:636\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(tapes, device, gradient_fn, interface, transform_program, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[39m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m no_interface_boundary_required:\n\u001b[0;32m--> 636\u001b[0m     results \u001b[39m=\u001b[39m inner_execute(tapes)\n\u001b[1;32m    637\u001b[0m     results \u001b[39m=\u001b[39m batch_fn(results)\n\u001b[1;32m    638\u001b[0m     \u001b[39mreturn\u001b[39;00m program_post_processing(results)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:255\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[0;34m(tapes, **_)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39mif\u001b[39;00m numpy_only:\n\u001b[1;32m    254\u001b[0m     tapes \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(qml\u001b[39m.\u001b[39mtransforms\u001b[39m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tapes)\n\u001b[0;32m--> 255\u001b[0m \u001b[39mreturn\u001b[39;00m cached_device_execution(tapes)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/interfaces/execution.py:377\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[0;34m(tapes, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[39mreturn\u001b[39;00m (res, []) \u001b[39mif\u001b[39;00m return_tuple \u001b[39melse\u001b[39;00m res\n\u001b[1;32m    374\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    375\u001b[0m     \u001b[39m# execute all unique tapes that do not exist in the cache\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[39m# convert to list as new device interface returns a tuple\u001b[39;00m\n\u001b[0;32m--> 377\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(fn(\u001b[39mtuple\u001b[39;49m(execution_tapes\u001b[39m.\u001b[39;49mvalues()), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    379\u001b[0m final_res \u001b[39m=\u001b[39m []\n\u001b[1;32m    381\u001b[0m \u001b[39mfor\u001b[39;00m i, tape \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tapes):\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/_qubit_device.py:629\u001b[0m, in \u001b[0;36mQubitDevice.batch_execute\u001b[0;34m(self, circuits)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[39mfor\u001b[39;00m circuit \u001b[39min\u001b[39;00m circuits:\n\u001b[1;32m    625\u001b[0m     \u001b[39m# we need to reset the device here, else it will\u001b[39;00m\n\u001b[1;32m    626\u001b[0m     \u001b[39m# not start the next computation in the zero state\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset()\n\u001b[0;32m--> 629\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute(circuit)\n\u001b[1;32m    630\u001b[0m     results\u001b[39m.\u001b[39mappend(res)\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtracker\u001b[39m.\u001b[39mactive:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/devices/default_qubit_torch.py:247\u001b[0m, in \u001b[0;36mDefaultQubitTorch.execute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[39mif\u001b[39;00m params_cuda_device \u001b[39m!=\u001b[39m specified_device_cuda:\n\u001b[1;32m    240\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    241\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTorch device \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_torch_device\u001b[39m}\u001b[39;00m\u001b[39m specified \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mupon PennyLane device creation does not match the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mTorch device of the gate parameters; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_torch_device\u001b[39m}\u001b[39;00m\u001b[39m will be used.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[0;32m--> 247\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mexecute(circuit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/_qubit_device.py:337\u001b[0m, in \u001b[0;36mQubitDevice.execute\u001b[0;34m(self, circuit, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_validity(circuit\u001b[39m.\u001b[39moperations, circuit\u001b[39m.\u001b[39mobservables)\n\u001b[1;32m    336\u001b[0m \u001b[39m# apply all circuit operations\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(circuit\u001b[39m.\u001b[39;49moperations, rotations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_diagonalizing_gates(circuit), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    339\u001b[0m \u001b[39m# generate computational basis samples\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshots \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m circuit\u001b[39m.\u001b[39mis_sampled:\n",
                        "File \u001b[0;32m~/Documents/repos.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/pennylane/devices/default_qubit.py:294\u001b[0m, in \u001b[0;36mDefaultQubit.apply\u001b[0;34m(self, operations, rotations, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_parametrized_evolution(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state, operation)\n\u001b[1;32m    293\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 294\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply_operation(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state, operation)\n\u001b[1;32m    296\u001b[0m \u001b[39m# store the pre-rotated state\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pre_rotated_state \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Run experiment\n",
                "results_schema = [\"accuracy\", \"training_time\", \"testing_time\"]\n",
                "experiment = Experiment(model, num_trials, results_schema)\n",
                "# experiment.partial(silent=silent)\n",
                "results = experiment(filename=filename)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print accuracy results\n",
                "metrics = (\"median\", \"mean\", \"max\", \"min\", \"std\")\n",
                "for name in results.columns:\n",
                "    col = results[name]\n",
                "    msg = (f\"{metric}={getattr(col, metric)()}\" for metric in metrics)\n",
                "    msg = \", \".join(msg)\n",
                "    msg = f\"{name}: {msg}\"\n",
                "    model.logger.info(msg)\n",
                "\n",
                "# Save aggregated loss history figure\n",
                "display(experiment.draw(filename))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c7967d85baf232544f00baec60c53642b018367ac4c489b1a4dde60b922cc6fa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
