{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging\n",
                "\n",
                "logging.basicConfig(level=logging.INFO)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.datasets import MNIST, FashionMNIST, CIFAR10\n",
                "from torch.optim import SGD, Adam\n",
                "from torch.nn import CrossEntropyLoss, MSELoss\n",
                "\n",
                "# from pennylane import NesterovMomentumOptimizer\n",
                "\n",
                "from qcc.ml.data import Data, BinaryData\n",
                "from qcc.ml.optimize import Optimizer\n",
                "from qcc.ml.data import ImageTransform, ImageTransform1D, ClassicalImageTransform\n",
                "from qcc.experiment import Experiment\n",
                "from qcc.ml.model import Model\n",
                "\n",
                "from pathlib import Path\n",
                "from qcc.file import new_dir\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz import MQCCOptimized # as Module\n",
                "# from qcc.quantum.pennylane.ansatz import QCNN as Module\n",
                "# from qcc.ml.cnn import ConvolutionalNeuralNetwork as Module\n",
                "from qcc.ml.mlp import MultiLayerPerceptron as Module\n",
                "# from qcc.ml.quanvolution import QuanvolutionalNeuralNetwork as Module\n",
                "# from qcc.ml.quantum import MQCCNonHybrid as Module\n",
                "\n",
                "# from qcc.quantum.pennylane.ansatz.basic import BasicFiltering6\n",
                "from qcc.quantum.pennylane.pyramid import Pyramid\n",
                "from qcc.quantum.pennylane.c2q import ConvolutionAngleFilter, ConvolutionComplexAngleFilter, ConvolutionFilter\n",
                "from qcc.quantum.pennylane.local import define_filter\n",
                "from qcc.ml.quantum import AnsatzFilter\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Meta parameters\n",
                "name = \"sdfljhvosdv\"\n",
                "filename = Path(f\"results/{name}\")\n",
                "num_trials = 1\n",
                "silent = False\n",
                "is_quantum = False\n",
                "\n",
                "# Ansatz parameters\n",
                "dims = (16, 16, 3, 1)\n",
                "num_layers = 4\n",
                "module_options = {\n",
                "    # \"U_kernel\": ConvolutionAngleFilter,\n",
                "    # \"pre_op\": True,\n",
                "    # \"num_features\": 4,\n",
                "    # \"U_fully_connected\": ConvolutionAngleFilter,\n",
                "    # \"pooling\": True,\n",
                "    # \"kernel_shape\": (2, 2),\n",
                "    # \"q2c_method\": \"parity\"\n",
                "    # \"bias\": False\n",
                "    # \"ansatz\": MQCCOptimized\n",
                "}\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-11-26 17:08:15,409: (multilayerperceptron) Circuit ID: sdfljhvosdv\n",
                        "2023-11-26 17:08:15,410: (multilayerperceptron) module=MultiLayerPerceptron(\n",
                        "  (0): Flatten(start_dim=1, end_dim=-1)\n",
                        "  (1): Linear(in_features=768, out_features=768, bias=True)\n",
                        "  (2): ReLU()\n",
                        "  (3): Linear(in_features=768, out_features=768, bias=True)\n",
                        "  (4): ReLU()\n",
                        "  (5): Linear(in_features=768, out_features=768, bias=True)\n",
                        "  (6): ReLU()\n",
                        "  (7): Linear(in_features=768, out_features=2, bias=True)\n",
                        ")\n",
                        "2023-11-26 17:08:15,410: (multilayerperceptron) data=BinaryData(dataset=<class 'torchvision.datasets.cifar.CIFAR10'>, transform=image_transform_classical, target_transform=None, batch_size=(8, 8), classes=[0, 1])\n",
                        "2023-11-26 17:08:15,411: (multilayerperceptron) optimizer=<class 'torch.optim.adam.Adam'>, self.args=(), self.kwargs={}\n",
                        "2023-11-26 17:08:15,411: (multilayerperceptron) loss=CrossEntropyLoss()\n",
                        "2023-11-26 17:08:15,412: (multilayerperceptron) num_trials=1\n",
                        "2023-11-26 17:08:15,412: (multilayerperceptron) dims=(16, 16, 3, 1)\n",
                        "2023-11-26 17:08:15,412: (multilayerperceptron) num_layers=4\n",
                        "2023-11-26 17:08:15,412: (multilayerperceptron) module_options={}\n"
                    ]
                }
            ],
            "source": [
                "filename = new_dir(filename, overwrite=True)\n",
                "filename = filename / name\n",
                "\n",
                "if is_quantum:\n",
                "    module = Module.from_dims\n",
                "else:\n",
                "    module = Module\n",
                "\n",
                "# Create module\n",
                "module = module(\n",
                "    dims,\n",
                "    num_layers=num_layers,\n",
                "    **module_options,\n",
                ")\n",
                "data = BinaryData(\n",
                "    CIFAR10,\n",
                "    ImageTransform1D(dims) if is_quantum else ClassicalImageTransform(dims),\n",
                "    batch_size=(8,8),\n",
                ")\n",
                "optimizer = Optimizer(Adam)\n",
                "loss = CrossEntropyLoss()\n",
                "model = Model.with_logging(module, data, optimizer, loss, epoch=8)\n",
                "\n",
                "# Log important values\n",
                "model.logger.info(f\"Circuit ID: {name}\")\n",
                "model.logger.info(f\"{module=}\")\n",
                "model.logger.info(f\"{data=}\")\n",
                "model.logger.info(f\"{optimizer=}\")\n",
                "model.logger.info(f\"{loss=}\")\n",
                "\n",
                "model.logger.info(f\"{num_trials=}\")\n",
                "model.logger.info(f\"{dims=}\")\n",
                "model.logger.info(f\"{num_layers=}\")\n",
                "# model.logger.info(f\"{1=}\")\n",
                "model.logger.info(f\"{module_options=}\")\n",
                "\n",
                "# Save circuit drawing\n",
                "if is_quantum:\n",
                "    draw_path = filename.with_stem(f\"{name}_circuit\")\n",
                "    module.draw(filename=draw_path, decompose=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Files already downloaded and verified\n",
                        "Files already downloaded and verified\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2023-11-26 17:08:16,769: (multilayerperceptron) Number of Parameters: 1773314\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "\u001b[1;32m/Users/mingyoungjeng/Documents/Spring 2023.nosync/quantum-convolutional-classifier/test/test.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(model, num_trials, results_schema)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# experiment.partial(silent=silent)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mingyoungjeng/Documents/Spring%202023.nosync/quantum-convolutional-classifier/test/test.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m results \u001b[39m=\u001b[39m experiment(filename\u001b[39m=\u001b[39;49mfilename)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:154\u001b[0m, in \u001b[0;36mExperiment.__call__\u001b[0;34m(self, filename, parallel)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_trials):\n\u001b[0;32m--> 154\u001b[0m         dfs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_trial(i \u001b[39m+\u001b[39;49m offset, rename\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_trials \u001b[39m>\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_merge_dfs(dfs, filename)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdfs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mresults\u001b[39m\u001b[39m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/experiment/experiment.py:68\u001b[0m, in \u001b[0;36mExperiment._run_trial\u001b[0;34m(self, idx, cls, rename)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m Logger\u001b[39m.\u001b[39mcopy(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger, name\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m_trial_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[39m# Perform trial and get results\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m results_df \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39mDataFrame([\u001b[39mcls\u001b[39;49m()], schema\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults_schema)\n\u001b[1;32m     70\u001b[0m \u001b[39m# Combine DataFrames\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m rename:\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/ml/model.py:46\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, params, silent)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch):\n\u001b[1;32m     45\u001b[0m     now \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time()\n\u001b[0;32m---> 46\u001b[0m     parameters \u001b[39m=\u001b[39m train(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodule, opt, training_dataloader, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cost)\n\u001b[1;32m     47\u001b[0m     training_time \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mthread_time() \u001b[39m-\u001b[39m now\n\u001b[1;32m     49\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTraining took \u001b[39m\u001b[39m{\u001b[39;00mtraining_time\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/src/qcc/ml/optimize.py:113\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(fn, optimizer, training_dataloader, cost_fn, epoch, params)\u001b[0m\n\u001b[1;32m    111\u001b[0m     fn \u001b[39m=\u001b[39m fn\u001b[39m.\u001b[39mto(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mfor\u001b[39;49;00m j, (data, labels) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(training_dataloader):\n\u001b[1;32m    114\u001b[0m         \u001b[39mif\u001b[39;49;00m USE_CUDA:\n\u001b[1;32m    115\u001b[0m             data, labels \u001b[39m=\u001b[39;49m data\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m), labels\u001b[39m.\u001b[39;49mto(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, \u001b[39m\"\u001b[39m\u001b[39m__getitems__\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset\u001b[39m.\u001b[39;49m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;49;00m idx \u001b[39min\u001b[39;49;00m indices]\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torch/utils/data/dataset.py:364\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices])  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 364\u001b[0m     \u001b[39mreturn\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m indices]\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/torchvision/datasets/cifar.py:115\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    111\u001b[0m img, target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[index], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets[index]\n\u001b[1;32m    113\u001b[0m \u001b[39m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39;49mfromarray(img)\n\u001b[1;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(img)\n",
                        "File \u001b[0;32m~/Documents/Spring 2023.nosync/quantum-convolutional-classifier/.env/lib/python3.11/site-packages/PIL/Image.py:3114\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3112\u001b[0m \u001b[39mif\u001b[39;00m strides \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39mtobytes\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 3114\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49mtobytes()\n\u001b[1;32m   3115\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3116\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mtostring()\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "# Run experiment\n",
                "results_schema = [\"accuracy\", \"training_time\", \"testing_time\"]\n",
                "experiment = Experiment(model, num_trials, results_schema)\n",
                "# experiment.partial(silent=silent)\n",
                "results = experiment(filename=filename)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Print accuracy results\n",
                "metrics = (\"median\", \"mean\", \"max\", \"min\", \"std\")\n",
                "for name in results.columns:\n",
                "    col = results[name]\n",
                "    msg = (f\"{metric}={getattr(col, metric)()}\" for metric in metrics)\n",
                "    msg = \", \".join(msg)\n",
                "    msg = f\"{name}: {msg}\"\n",
                "    model.logger.info(msg)\n",
                "\n",
                "# Save aggregated loss history figure\n",
                "display(experiment.draw(filename))\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "c7967d85baf232544f00baec60c53642b018367ac4c489b1a4dde60b922cc6fa"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
