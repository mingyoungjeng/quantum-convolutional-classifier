{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 32\n",
    "out_features = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[ 0.1513, -0.0389,  0.1687,  0.0349, -0.1164, -0.0033,  0.0095, -0.1475,\n",
       "           0.1628, -0.0405,  0.1569, -0.0154, -0.0783, -0.1448,  0.1442,  0.0269,\n",
       "           0.0571, -0.1700,  0.1089,  0.1220, -0.0090, -0.0050, -0.0158,  0.1580,\n",
       "          -0.1757,  0.1742, -0.0705,  0.1285, -0.0969, -0.0182,  0.0689, -0.0204],\n",
       "         [-0.1291,  0.1670,  0.1477, -0.1322, -0.1211, -0.0441, -0.1219,  0.1027,\n",
       "          -0.0129, -0.0116,  0.1102, -0.0169,  0.1627, -0.0069, -0.1022,  0.0124,\n",
       "          -0.0481,  0.0207, -0.1577, -0.1467, -0.0311,  0.0491,  0.0452,  0.0696,\n",
       "          -0.0294, -0.0902, -0.0552,  0.1085, -0.1381, -0.1273,  0.0828,  0.0507],\n",
       "         [ 0.1741, -0.1677,  0.0723,  0.0743,  0.0354, -0.1268,  0.0203, -0.1334,\n",
       "          -0.0973, -0.1454,  0.0155, -0.0670,  0.0295,  0.0008,  0.0477, -0.0699,\n",
       "          -0.0286,  0.1509,  0.0728,  0.0390, -0.0445, -0.0005,  0.0225,  0.1637,\n",
       "          -0.0837,  0.0490, -0.1259,  0.1600,  0.0219,  0.0322, -0.0630, -0.0809],\n",
       "         [-0.1749, -0.0976,  0.1564,  0.0677, -0.1166,  0.0946,  0.1351, -0.1093,\n",
       "           0.0488, -0.0933,  0.1084, -0.1235,  0.0061, -0.0793, -0.1200,  0.0097,\n",
       "          -0.1568, -0.1705,  0.0525,  0.1466, -0.1107,  0.0675,  0.1200,  0.0388,\n",
       "           0.0765, -0.0250,  0.1634,  0.0087,  0.0737, -0.0611, -0.1061, -0.0837],\n",
       "         [-0.0586,  0.1238, -0.0074, -0.0796, -0.0564,  0.1495, -0.0146,  0.1300,\n",
       "           0.1633, -0.1073, -0.0085,  0.0631, -0.0455, -0.0414,  0.0616,  0.0160,\n",
       "           0.1362, -0.0469,  0.0198, -0.0251,  0.1725, -0.1311, -0.1539,  0.0233,\n",
       "          -0.1582, -0.1194,  0.0788, -0.1642, -0.0463,  0.0661,  0.0068, -0.1457],\n",
       "         [-0.1419,  0.0455,  0.1008, -0.1492,  0.1438,  0.1280,  0.0997, -0.0431,\n",
       "           0.0299, -0.0118,  0.1137, -0.0768, -0.0020, -0.1352, -0.1132, -0.0572,\n",
       "          -0.1521,  0.0276,  0.0041, -0.1043, -0.0527, -0.0760,  0.0550, -0.1124,\n",
       "           0.0217,  0.0084,  0.0499, -0.1447,  0.0317,  0.1692,  0.0388, -0.1264],\n",
       "         [-0.1124, -0.0749,  0.0652, -0.1635,  0.1497,  0.0040, -0.0770, -0.0164,\n",
       "           0.1020,  0.1480,  0.0352,  0.1264,  0.1759, -0.0375, -0.1459,  0.1364,\n",
       "           0.0371, -0.0913,  0.1724, -0.0570, -0.1128,  0.1548, -0.0606, -0.1335,\n",
       "           0.1411, -0.0378,  0.0175,  0.0246,  0.1448,  0.1299,  0.0013, -0.0572],\n",
       "         [ 0.1291,  0.1430, -0.1106,  0.0978, -0.0089,  0.1541,  0.0417,  0.1254,\n",
       "           0.0719, -0.1174, -0.1164, -0.0856,  0.0776, -0.1106, -0.0907,  0.0356,\n",
       "           0.0856,  0.1103, -0.0809, -0.0838,  0.0995, -0.1217, -0.1704,  0.1386,\n",
       "           0.0973,  0.0949, -0.1391, -0.1482,  0.1358, -0.0486,  0.1459, -0.1601]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.1628, -0.0288,  0.0273, -0.0890, -0.1744,  0.1371, -0.0224,  0.0176],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "\n",
    "classical = Linear(in_features, out_features)\n",
    "classical.weight, classical.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.6922, 6.1755, 2.0536, 0.4415, 2.4870, 4.7588, 2.1313, 0.7777, 2.1181,\n",
       "         3.4901, 5.8533, 3.9499, 1.5229, 3.7413, 6.2067, 4.4179, 4.2624, 4.8898,\n",
       "         5.1127, 1.0826, 0.3721, 5.8603, 1.0734, 2.5090, 5.0157, 4.2063, 1.2370,\n",
       "         0.0681, 4.5753, 4.7051, 2.6940, 2.8808, 5.6310, 1.5579, 4.5407, 0.1777,\n",
       "         5.1019, 3.6090, 1.5825, 3.0374, 0.5733, 4.0572, 5.9597, 1.6700, 0.9190,\n",
       "         2.8603, 3.6177, 2.4843, 2.2964, 0.6688, 5.6951, 0.9304, 5.8388, 4.0105,\n",
       "         4.8461, 3.6462, 2.9529, 6.1268, 2.9129, 2.8119, 1.5548, 4.1798, 3.8909,\n",
       "         5.3295, 3.9538, 1.7449, 4.1877, 5.0597, 0.5994, 5.3571, 4.6058, 4.9971,\n",
       "         4.2458, 6.2021, 1.4549, 2.6197, 4.5870, 1.8192, 3.0402, 4.5668, 3.0834,\n",
       "         5.2847, 2.3816, 0.4134, 1.6715, 3.5202, 1.0501, 1.0092, 1.4187, 3.6385,\n",
       "         0.7106, 2.8018, 2.6465, 5.7463, 4.4491, 4.1844, 3.2418, 2.8491, 4.3365,\n",
       "         4.3832, 6.2304, 6.1838, 3.4210, 0.5839, 2.7858, 4.0276, 0.2954, 1.0254,\n",
       "         2.3315, 4.5786, 4.9927, 1.9243, 2.4494, 1.9648, 0.1426, 1.3193, 5.2285,\n",
       "         1.1163, 4.8397, 1.7777, 3.8635, 4.2184, 1.0629, 3.5090, 0.2040, 5.9795,\n",
       "         5.6750, 3.8328, 6.2577, 0.7552, 1.0268, 2.6125, 4.2319, 2.7706, 3.6054,\n",
       "         0.2216, 6.1791, 0.9798, 4.3397, 1.6201, 4.5707, 0.8597, 2.3220, 3.2486,\n",
       "         1.5248, 4.0694, 4.5053, 2.8924, 1.8861, 4.9226, 1.1318, 1.9576, 4.4108,\n",
       "         6.0996, 6.1220, 2.7088, 4.6240, 4.6523, 6.1800, 4.7974, 5.5688, 4.9386,\n",
       "         3.2617, 4.1731, 4.3395, 3.3192, 6.2827, 6.1634, 1.6160, 2.1029, 1.7604,\n",
       "         5.7513, 5.3364, 0.1269, 1.3980, 1.3712, 2.6747, 6.0579, 1.9163, 1.7565,\n",
       "         4.9031, 5.8822, 5.9941, 5.9285, 1.5034, 2.5727, 5.8317, 6.1906, 4.0639,\n",
       "         5.5374, 2.7932, 1.4059, 4.4029, 4.9674, 2.9456, 3.6701, 4.1646, 2.3918,\n",
       "         2.2233, 5.7276, 4.6194, 2.9857, 1.5105, 5.7699, 1.2603, 2.6064, 4.1733,\n",
       "         4.5146, 3.2650, 0.1834, 3.3638, 2.6060, 4.0218, 3.8842, 2.7180, 5.8355,\n",
       "         6.1846, 3.9291, 5.4130, 5.1107, 3.3858, 3.8529, 3.6168, 2.3204, 5.3706,\n",
       "         1.5579, 5.2274, 3.2090, 0.6396, 5.9320, 0.1085, 1.3028, 5.0621, 5.1340,\n",
       "         0.2650, 5.0231, 1.5370, 3.5634, 2.1447, 2.0373, 2.6744, 5.4568, 0.4296,\n",
       "         2.5009, 2.2834, 3.1989, 0.3729, 5.8885, 0.1963, 0.9862, 5.5232, 0.1006,\n",
       "         0.9297, 4.0208, 6.1931, 5.0659], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0555, -0.0596,  0.1047, -0.0709,  0.0284, -0.1051, -0.0155, -0.1733],\n",
       "        requires_grad=True))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from qcc.quantum.pennylane.ansatz.fully_connected import FullyConnected\n",
    "from qcc.quantum.pennylane.c2q import ConvolutionFilter \n",
    "\n",
    "quantum = FullyConnected.from_dims(in_features, out_features, U_filter=ConvolutionFilter)\n",
    "quantum.weight, quantum.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "weight = torch.abs(classical.weight.T / torch.norm(classical.weight, dim=1)).T\n",
    "bias = classical.bias\n",
    "\n",
    "weight = torch.nn.Parameter(weight)\n",
    "bias = torch.nn.Parameter(bias)\n",
    "\n",
    "classical.weight, classical.bias = weight, bias\n",
    "quantum.weight, quantum.bias = torch.nn.Parameter(weight.flatten()), bias\n",
    "\n",
    "assert((classical.weight.flatten() == quantum.weight).all())\n",
    "assert((classical.bias == quantum.bias).all())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.nn.init.uniform_(torch.zeros(in_features))\n",
    "data = data / torch.abs(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6498, 4.8127, 4.6451, 5.0606, 4.6992, 4.7848, 4.8809, 5.3310],\n",
       "       grad_fn=<MvBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classical.weight @ data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.4870, 4.7840, 4.6724, 4.9716, 4.5248, 4.9218, 4.8586, 5.3486],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " tensor([[4.4870, 4.7840, 4.6724, 4.9716, 4.5248, 4.9218, 4.8586, 5.3486]],\n",
       "        dtype=torch.float64, grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "classical(data), quantum(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
